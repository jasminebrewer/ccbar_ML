{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e869bf",
   "metadata": {},
   "source": [
    "### Test a GNN example before trying it on your own data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9522c63",
   "metadata": {},
   "source": [
    "an example from https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial7/GNN_overview.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd678528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a135b9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "001cabcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "tu_dataset = TUDataset(root='/tmp/MUTAG', name='MUTAG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d507a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data object: Data(x=[3371, 7], edge_index=[2, 7442], edge_attr=[7442, 4], y=[188])\n",
      "Length: 188\n",
      "Average label: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.12/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data object:\", tu_dataset.data)\n",
    "print(\"Length:\", len(tu_dataset))\n",
    "print(f\"Average label: {tu_dataset.data.y.float().mean().item():4.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f328e2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "tu_dataset.shuffle()\n",
    "train_dataset = tu_dataset[:150]\n",
    "test_dataset = tu_dataset[150:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c429755b",
   "metadata": {},
   "source": [
    "The standard approach to handling GNN of data with many graphs (rather than e.g. one single big graph) is to put them all together in a big tensor except without any connections between unrelated graphs (see tutorial for explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e69554f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.12/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric.data as geom_data\n",
    "graph_train_loader = geom_data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "graph_val_loader = geom_data.DataLoader(test_dataset, batch_size=64) # Additional loader if you want to change to a larger dataset\n",
    "graph_test_loader = geom_data.DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "612124e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: DataBatch(edge_index=[2, 1512], x=[687, 7], edge_attr=[1512, 4], y=[38], batch=[687], ptr=[39])\n",
      "Labels: tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 0])\n",
      "Batch indices: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(graph_test_loader))\n",
    "print(\"Batch:\", batch)\n",
    "print(\"Labels:\", batch.y[:10])\n",
    "print(\"Batch indices:\", batch.batch[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9f3a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch_geometric.nn as geom_nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class GNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, c_in, c_hidden, c_out, num_layers=2, layer_name=\"GCN\", dp_rate=0.1, **kwargs):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Dimension of input features\n",
    "            c_hidden - Dimension of hidden features\n",
    "            c_out - Dimension of the output features. Usually number of classes in classification\n",
    "            num_layers - Number of \"hidden\" graph layers\n",
    "            layer_name - String of the graph layer to use\n",
    "            dp_rate - Dropout rate to apply throughout the network\n",
    "            kwargs - Additional arguments for the graph layer (e.g. number of heads for GAT)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        gnn_layer = gnn_layer_by_name[layer_name]\n",
    "\n",
    "        layers = []\n",
    "        in_channels, out_channels = c_in, c_hidden\n",
    "        for l_idx in range(num_layers-1):\n",
    "            layers += [\n",
    "                gnn_layer(in_channels=in_channels,\n",
    "                          out_channels=out_channels,\n",
    "                          **kwargs),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dp_rate)\n",
    "            ]\n",
    "            in_channels = c_hidden\n",
    "        layers += [gnn_layer(in_channels=in_channels,\n",
    "                             out_channels=c_out,\n",
    "                             **kwargs)]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            x - Input features per node\n",
    "            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "        \"\"\"\n",
    "        for l in self.layers:\n",
    "            # For graph layers, we need to add the \"edge_index\" tensor as additional input\n",
    "            # All PyTorch Geometric graph layer inherit the class \"MessagePassing\", hence\n",
    "            # we can simply check the class type.\n",
    "            if isinstance(l, geom_nn.MessagePassing):\n",
    "                x = l(x, edge_index)\n",
    "            else:\n",
    "                x = l(x)\n",
    "        return x\n",
    "\n",
    "class GraphGNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, c_in, c_hidden, c_out, dp_rate_linear=0.5, **kwargs):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Dimension of input features\n",
    "            c_hidden - Dimension of hidden features\n",
    "            c_out - Dimension of output features (usually number of classes)\n",
    "            dp_rate_linear - Dropout rate before the linear layer (usually much higher than inside the GNN)\n",
    "            kwargs - Additional arguments for the GNNModel object\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.GNN = GNNModel(c_in=c_in,\n",
    "                            c_hidden=c_hidden,\n",
    "                            c_out=c_hidden, # Not our prediction output yet!\n",
    "                            **kwargs)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Dropout(dp_rate_linear),\n",
    "            nn.Linear(c_hidden, c_out)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, batch_idx):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            x - Input features per node\n",
    "            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "            batch_idx - Index of batch element for each node\n",
    "        \"\"\"\n",
    "        x = self.GNN(x, edge_index)\n",
    "        x = geom_nn.global_mean_pool(x, batch_idx) # Average pooling\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a0e995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphLevelGNN(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, **model_kwargs):\n",
    "        super().__init__()\n",
    "        # Saving hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = GraphGNNModel(**model_kwargs)\n",
    "        self.loss_module = nn.BCEWithLogitsLoss() if self.hparams.c_out == 1 else nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, data, mode=\"train\"):\n",
    "        x, edge_index, batch_idx = data.x, data.edge_index, data.batch\n",
    "        x = self.model(x, edge_index, batch_idx)\n",
    "        x = x.squeeze(dim=-1)\n",
    "\n",
    "        if self.hparams.c_out == 1:\n",
    "            preds = (x > 0).float()\n",
    "            data.y = data.y.float()\n",
    "        else:\n",
    "            preds = x.argmax(dim=-1)\n",
    "        loss = self.loss_module(x, data.y)\n",
    "        acc = (preds == data.y).sum().float() / preds.shape[0]\n",
    "        return loss, acc\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=1e-2, weight_decay=0.0) # High lr because of small dataset and small model\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc = self.forward(batch, mode=\"train\")\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        _, acc = self.forward(batch, mode=\"val\")\n",
    "        self.log('val_acc', acc)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        _, acc = self.forward(batch, mode=\"test\")\n",
    "        self.log('test_acc', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06983fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "429293a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "CHECKPOINT_PATH = \"../saved_models/tutorial7\"\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "def train_graph_classifier(model_name, **model_kwargs):\n",
    "    pl.seed_everything(42)\n",
    "\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    root_dir = os.path.join(CHECKPOINT_PATH, \"GraphLevel\" + model_name)\n",
    "    os.makedirs(root_dir, exist_ok=True)\n",
    "    trainer = pl.Trainer(default_root_dir=root_dir,\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n",
    "                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "                         devices=1,\n",
    "                         max_epochs=500,\n",
    "                         enable_progress_bar=False)\n",
    "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"GraphLevel{model_name}.ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(\"Found pretrained model, loading...\")\n",
    "        model = GraphLevelGNN.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        pl.seed_everything(42)\n",
    "        model = GraphLevelGNN(c_in=tu_dataset.num_node_features,\n",
    "                              c_out=1 if tu_dataset.num_classes==2 else tu_dataset.num_classes,\n",
    "                              **model_kwargs)\n",
    "        trainer.fit(model, graph_train_loader, graph_val_loader)\n",
    "        model = GraphLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "    # Test best model on validation and test set\n",
    "    train_result = trainer.test(model, graph_train_loader, verbose=False)\n",
    "    test_result = trainer.test(model, graph_test_loader, verbose=False)\n",
    "    result = {\"test\": test_result[0]['test_acc'], \"train\": train_result[0]['test_acc']}\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c36cc6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tu_dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d792ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_layer_by_name = {\n",
    "    \"GCN\": geom_nn.GCNConv,\n",
    "    \"GAT\": geom_nn.GATConv,\n",
    "    \"GraphConv\": geom_nn.GraphConv\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99ec799e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Seed set to 42\n",
      "Missing logger folder: ../saved_models/tutorial7/GraphLevelGraphConv/lightning_logs\n",
      "\n",
      "  | Name        | Type              | Params\n",
      "--------------------------------------------------\n",
      "0 | model       | GraphGNNModel     | 266 K \n",
      "1 | loss_module | BCEWithLogitsLoss | 0     \n",
      "--------------------------------------------------\n",
      "266 K     Trainable params\n",
      "0         Non-trainable params\n",
      "266 K     Total params\n",
      "1.067     Total estimated model params size (MB)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=500` reached.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:492: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    }
   ],
   "source": [
    "model, result = train_graph_classifier(model_name=\"GraphConv\",\n",
    "                                       c_hidden=256,\n",
    "                                       layer_name=\"GraphConv\",\n",
    "                                       num_layers=3,\n",
    "                                       dp_rate_linear=0.5,\n",
    "                                       dp_rate=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0336b397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train performance: 92.76%\n",
      "Test performance:  92.11%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train performance: {100.0*result['train']:4.2f}%\")\n",
    "print(f\"Test performance:  {100.0*result['test']:4.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef28ba7b-1f00-4c8b-a6f0-2356c5b05f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "from functools import reduce\n",
    "\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn.utils import shuffle\n",
    "# from sklearn.utils import compute_class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "# from keras import layers, regularizers\n",
    "#layers = tf.keras.layers\n",
    "from tensorflow.keras import layers, models\n",
    "regularizers = tf.keras.regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8814b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files( filenames ):\n",
    "\n",
    "    params = []\n",
    "    flagged = []\n",
    "    event_number = []\n",
    "    for filename in filenames:\n",
    "        with open(filename, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            first_event=True\n",
    "            event_matrix = []\n",
    "            for line in reader:\n",
    "                splitline = line[0].split(' ')\n",
    "                if splitline[0]=='E':\n",
    "                    if not first_event: params.append(event_matrix)\n",
    "                    if first_event: first_event=False\n",
    "                    event_number.append(int(splitline[1]))\n",
    "                    flagged.append(int(splitline[2]))\n",
    "                    event_matrix = []\n",
    "                else:\n",
    "                    param_line = [float(s) for s in line]\n",
    "                    event_matrix.append(param_line)\n",
    "            params.append(event_matrix)\n",
    "\n",
    "    flagged = np.array(flagged, dtype=np.float64)\n",
    "    event_number = np.array(event_number, dtype=np.float64)\n",
    "    # zero-pad params\n",
    "    params_max_size = max(map(len, params))\n",
    "    params = np.array(list(map(lambda mat: np.pad(np.array(mat, dtype=np.float64), ((0, params_max_size - len(mat)), (0, 0))), params))).reshape((-1, params_max_size, 1, 1, 4))\n",
    "\n",
    "    return (params,flagged,event_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cc2b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['data/nodecay/jets_parton_nodecay_'+str(i)+'.dat' for i in range(1,11)]\n",
    "(params,flagged,event_number) = read_files(filenames)\n",
    "filenames = ['data/nodecay/jets_hadron_nodecay_'+str(i)+'.dat' for i in range(1,11)]\n",
    "(params_hadron,flagged_hadron,event_number_hadron) = read_files(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82dfe616",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = params_hadron\n",
    "flagged = flagged_hadron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a686fcb",
   "metadata": {},
   "source": [
    "Data has extreme class imbalance. Subsample the majority class to obtain a balance data set for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "379f464f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of flagged c-cbar events: 0.06374269005847953\n"
     ]
    }
   ],
   "source": [
    "is_flagged = flagged==1\n",
    "percentage = np.sum(is_flagged) / len(flagged)\n",
    "print('Percentage of flagged c-cbar events: '+str(percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2da49ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "flagged_params = params[ is_flagged ]\n",
    "unflagged_params = params[ ~is_flagged ]\n",
    "\n",
    "# downsample the unflagged (majority) class to be equal in length to the flagged (minority) class\n",
    "unflagged_indices = np.random.choice(unflagged_params.shape[0], size=len(flagged_params), replace=False)\n",
    "to_keep = unflagged_params[ unflagged_indices ]\n",
    "\n",
    "# re-append flagged and unflagged samples together\n",
    "keep_params = np.concatenate( (flagged_params, to_keep) )\n",
    "keep_flagged = np.concatenate( (np.ones(len(flagged_params)), np.zeros(len(to_keep))) )\n",
    "X_orig, y_orig = shuffle( keep_params, keep_flagged, random_state=0 ) # shuffle so that flagged and unflagged classes are all mixed together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d641f43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[ 1.65831e-03,  5.87835e-03,  3.52590e-01,  2.11000e+02]]],\n",
       "\n",
       "\n",
       "        [[[ 8.53011e-03,  2.75912e-01,  2.35697e-01, -2.11000e+02]]],\n",
       "\n",
       "\n",
       "        [[[ 2.83377e-02,  2.03387e-01, -1.42485e-01, -2.11000e+02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[ 4.23723e-03,  1.31423e-01, -3.63327e-01,  2.11000e+02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.96604e-03,  3.80450e-01, -8.68833e-02, -2.11000e+02]]],\n",
       "\n",
       "\n",
       "        [[[ 5.87365e-03,  3.41434e-01, -8.71167e-02, -2.11000e+02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[ 3.98320e-03, -2.95808e-01,  1.30156e-01,  2.20000e+01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.07891e-03,  2.92006e-01, -2.88342e-02,  2.20000e+01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.32148e-03,  1.15118e-01, -1.11258e-01,  2.20000e+01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00]]]],\n",
       "\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "\n",
       "       [[[[ 3.43544e-03,  2.24168e-01,  3.29820e-01,  2.20000e+01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.87391e-03, -5.71151e-02, -3.44349e-01,  2.20000e+01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.81846e-02,  2.82701e-02, -3.32996e-01,  2.11200e+03]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[ 1.61988e-03,  2.96225e-01,  2.58232e-01,  2.20000e+01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.65775e-02, -4.85734e-02,  3.29426e-01, -2.11000e+02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.54596e-02,  1.87385e-01,  2.64583e-01, -2.11000e+02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[ 4.33658e-03,  2.37023e-01,  2.95437e-01, -2.11000e+02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.07091e-02, -3.23617e-01,  2.31963e-01, -2.11200e+03]]],\n",
       "\n",
       "\n",
       "        [[[ 6.28274e-03, -1.42812e-01, -3.61930e-01,  2.11000e+02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00]]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "87683545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_encoding_layer(pdgs, max_tokens=None):\n",
    "  \n",
    "  # Create a layer that turns integers into indices.\n",
    "  index = layers.IntegerLookup(max_tokens=max_tokens)\n",
    "\n",
    "  # Learn the set of possible values and assign them a fixed integer index.\n",
    "  index.adapt( pdgs )\n",
    "\n",
    "  # Encode the integer indices.\n",
    "  encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size(), output_mode=\"one_hot\")\n",
    "\n",
    "  return lambda feature: encoder(index(feature))\n",
    "\n",
    "def do_category_encoding(dataset, category_index):\n",
    "\n",
    "    encoding_layer = category_encoding_layer( dataset[:,:,:,:,category_index] )\n",
    "    encoded_pdgs = np.asarray( encoding_layer( dataset[:,:,:,:,category_index] ) )\n",
    "    mask = np.ones( dataset.shape[4], bool)\n",
    "    mask[category_index] = False\n",
    "    dataset = np.concatenate( (dataset[:,:,:,:,mask], encoded_pdgs), axis=4 )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ec252",
   "metadata": {},
   "source": [
    "The most useful piece of information for understanding whether there is a c-cbar splitting inside of a jet is whether there is a c-cbar pair inside of the jet, but this information is often not accessible experimentally. As a test, we remove this information (either replacing charms with gluons or light quarks) and retrain the model to see how this impacts the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "65859624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_charms(pdgs, replacement):\n",
    "\n",
    "    assert replacement=='gluons' or replacement=='light quarks'\n",
    "\n",
    "    mask = np.isin(pdgs,[4,-4])\n",
    "\n",
    "    # replace with the id of gluons (21)\n",
    "    if replacement=='gluons':\n",
    "        pdgs[ mask ] = 21\n",
    "\n",
    "    # replace with up quarks (1)\n",
    "    elif replacement=='light quarks':\n",
    "        pdgs[ mask ] = np.sign( pdgs[mask] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2655616b",
   "metadata": {},
   "source": [
    "Make a copy of the original data, and then create two modifications for testing - either the charms are replaced by gluons, or by light (up) quarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2f102df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = 3 # the only category in this dataset is the particle id, which is at index 3\n",
    "\n",
    "X_orig_encoded = do_category_encoding(X_orig, category_index)\n",
    "x_train_orig, x_test_orig, y_train_orig, y_test_orig = train_test_split(X_orig_encoded, y_orig, test_size = .2, random_state = 0)\n",
    "\n",
    "# X = X_orig.copy()\n",
    "# replace_charms(X[:,:,:,:,category_index], 'light quarks')\n",
    "# X_encoded = do_category_encoding(X, category_index)\n",
    "# x_train_light, x_test_light, y_train_light, y_test_light = train_test_split(X_encoded, y_orig, test_size = .2, random_state = 0)\n",
    "# test_light = X[:,:,:,:,category_index].flatten()\n",
    "\n",
    "# X2 = X_orig.copy()\n",
    "# replace_charms(X2[:,:,:,:,category_index], 'gluons')\n",
    "# X_encoded = do_category_encoding(X2, category_index)\n",
    "# x_train_gluon, x_test_gluon, y_train_gluon, y_test_gluon = train_test_split(X_encoded, y_orig, test_size = .2, random_state = 0)\n",
    "# test_gluon = X2[:,:,:,:,category_index].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b048d17",
   "metadata": {},
   "source": [
    "Make the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "69d867f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReductionLayer(layers.Layer):\n",
    "    def __init__(self, name):\n",
    "        super(ReductionLayer, self).__init__(name=name)\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return mask\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.reduce_sum(inputs, axis=[1, 2, 3])\n",
    "\n",
    "\n",
    "def get_clf(\n",
    "    meta={},\n",
    "    hidden_layer_size=100,\n",
    "    observable_num=128,\n",
    "    activation='leaky_relu',\n",
    "    dropout=0.2,\n",
    "    kernel_reg=1e-5,\n",
    "    bias_reg=1e-5,\n",
    "    activity_reg=1e-5,\n",
    "    shape=x_train_orig.shape[1:]\n",
    "):\n",
    "    inputs = layers.Input(\n",
    "        shape=shape,\n",
    "        name=\"input\",\n",
    "    )\n",
    "    masked_inputs = layers.Masking(mask_value=0.0, name=\"masking\")(inputs)\n",
    "    dense_1 = layers.TimeDistributed(\n",
    "        layers.Dense(\n",
    "            hidden_layer_size,\n",
    "            activation=activation,\n",
    "            kernel_regularizer=regularizers.L2(kernel_reg),\n",
    "            bias_regularizer=regularizers.L2(bias_reg),\n",
    "            activity_regularizer=regularizers.L2(activity_reg),\n",
    "        ),\n",
    "        name=\"dense_1\",\n",
    "    )(masked_inputs)\n",
    "    dropout_1 = layers.Dropout(dropout)(dense_1)\n",
    "    dense_2 = layers.TimeDistributed(\n",
    "        layers.Dense(\n",
    "            hidden_layer_size,\n",
    "            activation=activation,\n",
    "            kernel_regularizer=regularizers.L2(kernel_reg),\n",
    "            bias_regularizer=regularizers.L2(bias_reg),\n",
    "            activity_regularizer=regularizers.L2(activity_reg),\n",
    "        ),\n",
    "        name=\"dense_2\",\n",
    "    )(dropout_1)\n",
    "    dropout_2 = layers.Dropout(dropout)(dense_2)\n",
    "    distributed_phi = layers.TimeDistributed(\n",
    "        layers.Dense(\n",
    "            observable_num,\n",
    "            activation=activation,\n",
    "            kernel_regularizer=regularizers.L2(kernel_reg),\n",
    "            bias_regularizer=regularizers.L2(bias_reg),\n",
    "            activity_regularizer=regularizers.L2(activity_reg),\n",
    "        ),\n",
    "        name=\"distributed_phi\",\n",
    "    )(dropout_2)\n",
    "    observables = ReductionLayer(name=\"observables\")(distributed_phi)\n",
    "    dropout_obs = layers.Dropout(dropout)(observables)\n",
    "    dense_3 = layers.Dense(\n",
    "        hidden_layer_size,\n",
    "        activation=activation,\n",
    "        kernel_regularizer=regularizers.L2(kernel_reg),\n",
    "        bias_regularizer=regularizers.L2(bias_reg),\n",
    "        activity_regularizer=regularizers.L2(activity_reg),\n",
    "        name=\"dense_3\",\n",
    "    )(dropout_obs)\n",
    "    dropout_3 = layers.Dropout(dropout)(dense_3)\n",
    "    dense_4 = layers.Dense(\n",
    "        hidden_layer_size,\n",
    "        activation=activation,\n",
    "        kernel_regularizer=regularizers.L2(kernel_reg),\n",
    "        bias_regularizer=regularizers.L2(bias_reg),\n",
    "        activity_regularizer=regularizers.L2(activity_reg),\n",
    "        name=\"dense_4\",\n",
    "    )(dropout_3)\n",
    "    dropout_4 = layers.Dropout(dropout)(dense_4)\n",
    "    dense_5 = layers.Dense(\n",
    "        hidden_layer_size,\n",
    "        activation=activation,\n",
    "        kernel_regularizer=regularizers.L2(kernel_reg),\n",
    "        bias_regularizer=regularizers.L2(bias_reg),\n",
    "        activity_regularizer=regularizers.L2(activity_reg),\n",
    "        name=\"dense_5\",\n",
    "    )(dropout_4)\n",
    "    dropout_5 = layers.Dropout(dropout)(dense_5)\n",
    "    output = layers.Dense(1, activation=\"sigmoid\", name=\"output\")(dropout_5)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2b295939",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = get_clf(dropout=0.2)\n",
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "# class_weights = compute_class_weight(\n",
    "#     class_weight=\"balanced\", classes=np.unique(flagged), y=flagged\n",
    "# )\n",
    "# class_weights /= sum(class_weights)\n",
    "# loss_fn = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "#     apply_class_balancing=True, alpha=0.5, gamma=2, from_logits=False\n",
    "# )\n",
    "\n",
    "clf.compile(optimizer=\"adam\", loss=loss_fn, metrics=[\"Accuracy\", \"AUC\", \"Precision\", \"Recall\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd1c16e",
   "metadata": {},
   "source": [
    "The most useful piece of information for understanding whether there is a c-cbar splitting inside of a jet is whether there is a c-cbar pair inside of the jet, but this information is often not accessible experimentally. As a test, we remove this information (either replacing charms with gluons or light quarks) and retrain the model to see how this impacts the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "20b402dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,400</span> │ masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │            │ any_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_36          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │ dropout_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │            │ any_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_37          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ distributed_phi     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │ dropout_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ any_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ observables         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ distributed_phi[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReductionLayer</span>)    │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_38          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ observables[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,900</span> │ dropout_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_39          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │ dropout_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_40          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │ dropout_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_41          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │ dropout_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│                     │ \u001b[38;5;34m43\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │ \u001b[38;5;34m43\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking (\u001b[38;5;33mMasking\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m43\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any_6 (\u001b[38;5;33mAny\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ not_equal_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,  │      \u001b[38;5;34m4,400\u001b[0m │ masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m100\u001b[0m)              │            │ any_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_36          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m100\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,  │     \u001b[38;5;34m10,100\u001b[0m │ dropout_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m100\u001b[0m)              │            │ any_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_37          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m100\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ distributed_phi     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,  │     \u001b[38;5;34m12,928\u001b[0m │ dropout_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m128\u001b[0m)              │            │ any_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ observables         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ distributed_phi[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mReductionLayer\u001b[0m)    │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_38          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ observables[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m12,900\u001b[0m │ dropout_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_39          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m10,100\u001b[0m │ dropout_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_40          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m10,100\u001b[0m │ dropout_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_41          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m101\u001b[0m │ dropout_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,629</span> (236.83 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m60,629\u001b[0m (236.83 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,629</span> (236.83 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m60,629\u001b[0m (236.83 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ad45b45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "dot_img_file = \"./model_1.png\"\n",
    "tf.keras.utils.plot_model(\n",
    "    clf,\n",
    "    to_file=dot_img_file,\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    show_layer_activations=True,\n",
    "    expand_nested=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "278f8b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 245ms/step - AUC: 0.5033 - Accuracy: 0.5040 - Precision: 0.5049 - Recall: 0.5074 - loss: 1.5634 - val_AUC: 0.5606 - val_Accuracy: 0.5057 - val_Precision: 0.6159 - val_Recall: 0.0710 - val_loss: 0.7127\n",
      "Epoch 2/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 248ms/step - AUC: 0.5571 - Accuracy: 0.5391 - Precision: 0.5417 - Recall: 0.5630 - loss: 0.6996 - val_AUC: 0.6730 - val_Accuracy: 0.6481 - val_Precision: 0.8956 - val_Recall: 0.3476 - val_loss: 0.6745\n",
      "Epoch 3/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 262ms/step - AUC: 0.6598 - Accuracy: 0.6399 - Precision: 0.7624 - Recall: 0.4105 - loss: 0.6425 - val_AUC: 0.6790 - val_Accuracy: 0.6525 - val_Precision: 0.8942 - val_Recall: 0.3582 - val_loss: 0.6528\n",
      "Epoch 4/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 267ms/step - AUC: 0.6528 - Accuracy: 0.6404 - Precision: 0.7925 - Recall: 0.3826 - loss: 0.6349 - val_AUC: 0.6783 - val_Accuracy: 0.6527 - val_Precision: 0.8943 - val_Recall: 0.3586 - val_loss: 0.6455\n",
      "Epoch 5/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 241ms/step - AUC: 0.6616 - Accuracy: 0.6486 - Precision: 0.8215 - Recall: 0.3773 - loss: 0.6277 - val_AUC: 0.6784 - val_Accuracy: 0.6525 - val_Precision: 0.8942 - val_Recall: 0.3582 - val_loss: 0.6378\n",
      "Epoch 6/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 247ms/step - AUC: 0.6658 - Accuracy: 0.6545 - Precision: 0.8438 - Recall: 0.3783 - loss: 0.6226 - val_AUC: 0.6795 - val_Accuracy: 0.6532 - val_Precision: 0.8945 - val_Recall: 0.3596 - val_loss: 0.6212\n",
      "Epoch 7/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 250ms/step - AUC: 0.6702 - Accuracy: 0.6533 - Precision: 0.8418 - Recall: 0.3769 - loss: 0.6213 - val_AUC: 0.6724 - val_Accuracy: 0.6522 - val_Precision: 0.8940 - val_Recall: 0.3575 - val_loss: 0.6271\n",
      "Epoch 8/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 247ms/step - AUC: 0.6605 - Accuracy: 0.6505 - Precision: 0.8562 - Recall: 0.3588 - loss: 0.6215 - val_AUC: 0.6779 - val_Accuracy: 0.6532 - val_Precision: 0.8959 - val_Recall: 0.3589 - val_loss: 0.6233\n",
      "Epoch 9/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 241ms/step - AUC: 0.6587 - Accuracy: 0.6448 - Precision: 0.8472 - Recall: 0.3614 - loss: 0.6218 - val_AUC: 0.6786 - val_Accuracy: 0.6507 - val_Precision: 0.9062 - val_Recall: 0.3483 - val_loss: 0.6346\n",
      "Epoch 10/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 243ms/step - AUC: 0.6697 - Accuracy: 0.6522 - Precision: 0.8569 - Recall: 0.3677 - loss: 0.6165 - val_AUC: 0.6776 - val_Accuracy: 0.6537 - val_Precision: 0.8948 - val_Recall: 0.3605 - val_loss: 0.6161\n",
      "Epoch 11/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 252ms/step - AUC: 0.6611 - Accuracy: 0.6510 - Precision: 0.8511 - Recall: 0.3673 - loss: 0.6200 - val_AUC: 0.6787 - val_Accuracy: 0.6541 - val_Precision: 0.8945 - val_Recall: 0.3614 - val_loss: 0.6121\n",
      "Epoch 12/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 245ms/step - AUC: 0.6601 - Accuracy: 0.6514 - Precision: 0.8608 - Recall: 0.3622 - loss: 0.6179 - val_AUC: 0.6787 - val_Accuracy: 0.6542 - val_Precision: 0.8950 - val_Recall: 0.3614 - val_loss: 0.6105\n",
      "Epoch 13/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 249ms/step - AUC: 0.6604 - Accuracy: 0.6541 - Precision: 0.8699 - Recall: 0.3567 - loss: 0.6171 - val_AUC: 0.6777 - val_Accuracy: 0.6542 - val_Precision: 0.8950 - val_Recall: 0.3614 - val_loss: 0.6110\n",
      "Epoch 14/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 243ms/step - AUC: 0.6705 - Accuracy: 0.6556 - Precision: 0.8584 - Recall: 0.3700 - loss: 0.6144 - val_AUC: 0.6765 - val_Accuracy: 0.6538 - val_Precision: 0.8976 - val_Recall: 0.3593 - val_loss: 0.6150\n",
      "Epoch 15/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 251ms/step - AUC: 0.6607 - Accuracy: 0.6496 - Precision: 0.8592 - Recall: 0.3595 - loss: 0.6186 - val_AUC: 0.6771 - val_Accuracy: 0.6533 - val_Precision: 0.9026 - val_Recall: 0.3558 - val_loss: 0.6153\n",
      "Epoch 16/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 247ms/step - AUC: 0.6712 - Accuracy: 0.6584 - Precision: 0.8688 - Recall: 0.3688 - loss: 0.6147 - val_AUC: 0.6770 - val_Accuracy: 0.6547 - val_Precision: 0.8948 - val_Recall: 0.3626 - val_loss: 0.6082\n",
      "Epoch 17/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 247ms/step - AUC: 0.6676 - Accuracy: 0.6563 - Precision: 0.8781 - Recall: 0.3652 - loss: 0.6120 - val_AUC: 0.6762 - val_Accuracy: 0.6545 - val_Precision: 0.8947 - val_Recall: 0.3624 - val_loss: 0.6088\n",
      "Epoch 18/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 256ms/step - AUC: 0.6684 - Accuracy: 0.6535 - Precision: 0.8694 - Recall: 0.3666 - loss: 0.6106 - val_AUC: 0.6796 - val_Accuracy: 0.6551 - val_Precision: 0.8946 - val_Recall: 0.3638 - val_loss: 0.6090\n",
      "Epoch 19/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 247ms/step - AUC: 0.6676 - Accuracy: 0.6514 - Precision: 0.8495 - Recall: 0.3739 - loss: 0.6136 - val_AUC: 0.6794 - val_Accuracy: 0.6543 - val_Precision: 0.8960 - val_Recall: 0.3612 - val_loss: 0.6093\n",
      "Epoch 20/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 240ms/step - AUC: 0.6633 - Accuracy: 0.6566 - Precision: 0.8695 - Recall: 0.3660 - loss: 0.6116 - val_AUC: 0.6774 - val_Accuracy: 0.6558 - val_Precision: 0.8968 - val_Recall: 0.3643 - val_loss: 0.6068\n",
      "Epoch 21/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 247ms/step - AUC: 0.6622 - Accuracy: 0.6517 - Precision: 0.8691 - Recall: 0.3612 - loss: 0.6130 - val_AUC: 0.6760 - val_Accuracy: 0.6554 - val_Precision: 0.8943 - val_Recall: 0.3645 - val_loss: 0.6066\n",
      "Epoch 22/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 241ms/step - AUC: 0.6723 - Accuracy: 0.6566 - Precision: 0.8748 - Recall: 0.3676 - loss: 0.6105 - val_AUC: 0.6785 - val_Accuracy: 0.6552 - val_Precision: 0.8946 - val_Recall: 0.3640 - val_loss: 0.6070\n",
      "Epoch 23/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 255ms/step - AUC: 0.6637 - Accuracy: 0.6535 - Precision: 0.8754 - Recall: 0.3604 - loss: 0.6123 - val_AUC: 0.6760 - val_Accuracy: 0.6543 - val_Precision: 0.8969 - val_Recall: 0.3607 - val_loss: 0.6084\n",
      "Epoch 24/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 245ms/step - AUC: 0.6604 - Accuracy: 0.6497 - Precision: 0.8831 - Recall: 0.3557 - loss: 0.6138 - val_AUC: 0.6768 - val_Accuracy: 0.6523 - val_Precision: 0.9134 - val_Recall: 0.3483 - val_loss: 0.6147\n",
      "Epoch 25/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 245ms/step - AUC: 0.6686 - Accuracy: 0.6492 - Precision: 0.8511 - Recall: 0.3576 - loss: 0.6150 - val_AUC: 0.6713 - val_Accuracy: 0.6555 - val_Precision: 0.8939 - val_Recall: 0.3650 - val_loss: 0.6063\n",
      "Epoch 26/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 249ms/step - AUC: 0.6705 - Accuracy: 0.6559 - Precision: 0.8775 - Recall: 0.3592 - loss: 0.6107 - val_AUC: 0.6776 - val_Accuracy: 0.6541 - val_Precision: 0.9015 - val_Recall: 0.3579 - val_loss: 0.6085\n",
      "Epoch 27/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 241ms/step - AUC: 0.6633 - Accuracy: 0.6476 - Precision: 0.8683 - Recall: 0.3561 - loss: 0.6161 - val_AUC: 0.6757 - val_Accuracy: 0.6545 - val_Precision: 0.9027 - val_Recall: 0.3584 - val_loss: 0.6078\n",
      "Epoch 28/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 246ms/step - AUC: 0.6636 - Accuracy: 0.6549 - Precision: 0.8726 - Recall: 0.3588 - loss: 0.6109 - val_AUC: 0.6776 - val_Accuracy: 0.6557 - val_Precision: 0.8963 - val_Recall: 0.3643 - val_loss: 0.6055\n",
      "Epoch 29/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 243ms/step - AUC: 0.6608 - Accuracy: 0.6506 - Precision: 0.8720 - Recall: 0.3518 - loss: 0.6129 - val_AUC: 0.6753 - val_Accuracy: 0.6547 - val_Precision: 0.8999 - val_Recall: 0.3600 - val_loss: 0.6070\n",
      "Epoch 30/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 244ms/step - AUC: 0.6671 - Accuracy: 0.6541 - Precision: 0.8761 - Recall: 0.3630 - loss: 0.6114 - val_AUC: 0.6785 - val_Accuracy: 0.6539 - val_Precision: 0.9024 - val_Recall: 0.3572 - val_loss: 0.6062\n",
      "Epoch 31/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 241ms/step - AUC: 0.6650 - Accuracy: 0.6535 - Precision: 0.8733 - Recall: 0.3568 - loss: 0.6128 - val_AUC: 0.6776 - val_Accuracy: 0.6555 - val_Precision: 0.8971 - val_Recall: 0.3633 - val_loss: 0.6060\n",
      "Epoch 32/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 246ms/step - AUC: 0.6639 - Accuracy: 0.6560 - Precision: 0.8686 - Recall: 0.3614 - loss: 0.6114 - val_AUC: 0.6779 - val_Accuracy: 0.6529 - val_Precision: 0.9096 - val_Recall: 0.3514 - val_loss: 0.6089\n",
      "Epoch 33/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 257ms/step - AUC: 0.6689 - Accuracy: 0.6580 - Precision: 0.8853 - Recall: 0.3588 - loss: 0.6091 - val_AUC: 0.6768 - val_Accuracy: 0.6548 - val_Precision: 0.9028 - val_Recall: 0.3589 - val_loss: 0.6050\n",
      "Epoch 34/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 250ms/step - AUC: 0.6645 - Accuracy: 0.6530 - Precision: 0.8920 - Recall: 0.3526 - loss: 0.6091 - val_AUC: 0.6787 - val_Accuracy: 0.6539 - val_Precision: 0.9014 - val_Recall: 0.3577 - val_loss: 0.6066\n",
      "Epoch 35/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 242ms/step - AUC: 0.6668 - Accuracy: 0.6562 - Precision: 0.8787 - Recall: 0.3560 - loss: 0.6087 - val_AUC: 0.6743 - val_Accuracy: 0.6555 - val_Precision: 0.8971 - val_Recall: 0.3633 - val_loss: 0.6044\n",
      "Epoch 36/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 243ms/step - AUC: 0.6540 - Accuracy: 0.6509 - Precision: 0.8768 - Recall: 0.3517 - loss: 0.6134 - val_AUC: 0.6754 - val_Accuracy: 0.6549 - val_Precision: 0.9038 - val_Recall: 0.3586 - val_loss: 0.6043\n",
      "Epoch 37/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 239ms/step - AUC: 0.6663 - Accuracy: 0.6531 - Precision: 0.8795 - Recall: 0.3530 - loss: 0.6110 - val_AUC: 0.6742 - val_Accuracy: 0.6522 - val_Precision: 0.9103 - val_Recall: 0.3495 - val_loss: 0.6102\n",
      "Epoch 38/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 246ms/step - AUC: 0.6608 - Accuracy: 0.6592 - Precision: 0.8853 - Recall: 0.3596 - loss: 0.6090 - val_AUC: 0.6752 - val_Accuracy: 0.6558 - val_Precision: 0.8959 - val_Recall: 0.3647 - val_loss: 0.6057\n",
      "Epoch 39/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 256ms/step - AUC: 0.6662 - Accuracy: 0.6509 - Precision: 0.8516 - Recall: 0.3644 - loss: 0.6127 - val_AUC: 0.6769 - val_Accuracy: 0.6556 - val_Precision: 0.9027 - val_Recall: 0.3607 - val_loss: 0.6045\n",
      "Epoch 40/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 248ms/step - AUC: 0.6605 - Accuracy: 0.6538 - Precision: 0.8793 - Recall: 0.3543 - loss: 0.6119 - val_AUC: 0.6766 - val_Accuracy: 0.6555 - val_Precision: 0.8961 - val_Recall: 0.3638 - val_loss: 0.6041\n",
      "Epoch 41/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 240ms/step - AUC: 0.6643 - Accuracy: 0.6523 - Precision: 0.8773 - Recall: 0.3582 - loss: 0.6101 - val_AUC: 0.6763 - val_Accuracy: 0.6555 - val_Precision: 0.8971 - val_Recall: 0.3633 - val_loss: 0.6047\n",
      "Epoch 42/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 248ms/step - AUC: 0.6697 - Accuracy: 0.6549 - Precision: 0.8819 - Recall: 0.3592 - loss: 0.6062 - val_AUC: 0.6775 - val_Accuracy: 0.6550 - val_Precision: 0.9034 - val_Recall: 0.3591 - val_loss: 0.6045\n",
      "Epoch 43/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 242ms/step - AUC: 0.6698 - Accuracy: 0.6594 - Precision: 0.8746 - Recall: 0.3679 - loss: 0.6058 - val_AUC: 0.6779 - val_Accuracy: 0.6554 - val_Precision: 0.8979 - val_Recall: 0.3626 - val_loss: 0.6040\n",
      "Epoch 44/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 237ms/step - AUC: 0.6600 - Accuracy: 0.6522 - Precision: 0.8862 - Recall: 0.3534 - loss: 0.6110 - val_AUC: 0.6745 - val_Accuracy: 0.6543 - val_Precision: 0.9045 - val_Recall: 0.3570 - val_loss: 0.6052\n",
      "Epoch 45/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 242ms/step - AUC: 0.6676 - Accuracy: 0.6591 - Precision: 0.8882 - Recall: 0.3592 - loss: 0.6061 - val_AUC: 0.6757 - val_Accuracy: 0.6557 - val_Precision: 0.8972 - val_Recall: 0.3638 - val_loss: 0.6031\n",
      "Epoch 46/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 243ms/step - AUC: 0.6688 - Accuracy: 0.6551 - Precision: 0.8686 - Recall: 0.3649 - loss: 0.6089 - val_AUC: 0.6786 - val_Accuracy: 0.6557 - val_Precision: 0.9037 - val_Recall: 0.3605 - val_loss: 0.6036\n",
      "Epoch 47/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 239ms/step - AUC: 0.6603 - Accuracy: 0.6528 - Precision: 0.8834 - Recall: 0.3576 - loss: 0.6079 - val_AUC: 0.6768 - val_Accuracy: 0.6556 - val_Precision: 0.8953 - val_Recall: 0.3645 - val_loss: 0.6053\n",
      "Epoch 48/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 235ms/step - AUC: 0.6663 - Accuracy: 0.6552 - Precision: 0.8683 - Recall: 0.3584 - loss: 0.6101 - val_AUC: 0.6757 - val_Accuracy: 0.6554 - val_Precision: 0.8956 - val_Recall: 0.3638 - val_loss: 0.6040\n",
      "Epoch 49/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 231ms/step - AUC: 0.6619 - Accuracy: 0.6563 - Precision: 0.8770 - Recall: 0.3610 - loss: 0.6089 - val_AUC: 0.6788 - val_Accuracy: 0.6544 - val_Precision: 0.9040 - val_Recall: 0.3575 - val_loss: 0.6048\n",
      "Epoch 50/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 237ms/step - AUC: 0.6611 - Accuracy: 0.6563 - Precision: 0.8915 - Recall: 0.3553 - loss: 0.6064 - val_AUC: 0.6780 - val_Accuracy: 0.6552 - val_Precision: 0.9035 - val_Recall: 0.3596 - val_loss: 0.6023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2efdecbf0>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    x_train_orig,\n",
    "    y_train_orig,\n",
    "    epochs=50,\n",
    "    batch_size=250,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c2399890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - AUC: 0.6612 - Accuracy: 0.6569 - Precision: 0.8826 - Recall: 0.3494 - loss: 0.6109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6044131517410278,\n",
       " 0.6714734435081482,\n",
       " 0.6614008545875549,\n",
       " 0.891566276550293,\n",
       " 0.35693612694740295]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.evaluate(x_test_orig,y_test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "7ab17c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3558"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf.predict(x_test_orig)\n",
    "binary_predictions = [1 if pred>0.5 else 0 for pred in preds]\n",
    "(binary_predictions!=y_test_orig).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "45121c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10508"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ee923a",
   "metadata": {},
   "source": [
    "Now, try the more difficult thing where you \"mislabel\" the charm quarks as up quarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2d6e09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - AUC: 0.5755 - Accuracy: 0.5555 - Precision: 0.5602 - Recall: 0.5348 - loss: 0.9910 - val_AUC: 0.9531 - val_Accuracy: 0.8774 - val_Precision: 0.9101 - val_Recall: 0.8328 - val_loss: 0.3812\n",
      "Epoch 2/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - AUC: 0.9358 - Accuracy: 0.8915 - Precision: 0.8625 - Recall: 0.9301 - loss: 0.3592 - val_AUC: 0.9584 - val_Accuracy: 0.9397 - val_Precision: 0.8935 - val_Recall: 0.9960 - val_loss: 0.2616\n",
      "Epoch 3/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - AUC: 0.9509 - Accuracy: 0.9291 - Precision: 0.8864 - Recall: 0.9849 - loss: 0.2797 - val_AUC: 0.9618 - val_Accuracy: 0.9410 - val_Precision: 0.8928 - val_Recall: 1.0000 - val_loss: 0.2408\n",
      "Epoch 4/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - AUC: 0.9565 - Accuracy: 0.9337 - Precision: 0.8896 - Recall: 0.9905 - loss: 0.2533 - val_AUC: 0.9657 - val_Accuracy: 0.9413 - val_Precision: 0.8933 - val_Recall: 1.0000 - val_loss: 0.2380\n",
      "Epoch 5/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - AUC: 0.9546 - Accuracy: 0.9348 - Precision: 0.8929 - Recall: 0.9908 - loss: 0.2458 - val_AUC: 0.9694 - val_Accuracy: 0.9400 - val_Precision: 0.8930 - val_Recall: 0.9973 - val_loss: 0.2239\n",
      "Epoch 6/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - AUC: 0.9601 - Accuracy: 0.9339 - Precision: 0.8889 - Recall: 0.9928 - loss: 0.2341 - val_AUC: 0.9706 - val_Accuracy: 0.9416 - val_Precision: 0.8938 - val_Recall: 1.0000 - val_loss: 0.2091\n",
      "Epoch 7/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - AUC: 0.9617 - Accuracy: 0.9359 - Precision: 0.8949 - Recall: 0.9902 - loss: 0.2254 - val_AUC: 0.9695 - val_Accuracy: 0.9416 - val_Precision: 0.8938 - val_Recall: 1.0000 - val_loss: 0.2124\n",
      "Epoch 8/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - AUC: 0.9634 - Accuracy: 0.9414 - Precision: 0.9008 - Recall: 0.9934 - loss: 0.2100 - val_AUC: 0.9704 - val_Accuracy: 0.9429 - val_Precision: 0.8960 - val_Recall: 1.0000 - val_loss: 0.1987\n",
      "Epoch 9/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - AUC: 0.9659 - Accuracy: 0.9411 - Precision: 0.8991 - Recall: 0.9932 - loss: 0.2044 - val_AUC: 0.9702 - val_Accuracy: 0.9429 - val_Precision: 0.8960 - val_Recall: 1.0000 - val_loss: 0.2083\n",
      "Epoch 10/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - AUC: 0.9619 - Accuracy: 0.9419 - Precision: 0.9023 - Recall: 0.9941 - loss: 0.2081 - val_AUC: 0.9705 - val_Accuracy: 0.9429 - val_Precision: 0.8960 - val_Recall: 1.0000 - val_loss: 0.1994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2edb5f800>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del clf\n",
    "clf = get_clf(dropout=0.2,shape=x_train_light.shape[1:])\n",
    "clf.compile(optimizer=\"adam\", loss=loss_fn, metrics=[\"Accuracy\", \"AUC\", \"Precision\", \"Recall\"])\n",
    "\n",
    "clf.fit(\n",
    "    x_train_light,\n",
    "    y_train_light,\n",
    "    epochs=50,\n",
    "    batch_size=250,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe42421d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - AUC: 0.9560 - Accuracy: 0.8786 - Precision: 0.9102 - Recall: 0.8321 - loss: 0.3460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34794682264328003,\n",
       " 0.9572073221206665,\n",
       " 0.8745108246803284,\n",
       " 0.9062857031822205,\n",
       " 0.8334209322929382]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.evaluate(x_test_light,y_test_light)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49137813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "481"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf.predict(x_test_light)\n",
    "binary_predictions = [1 if pred>0.5 else 0 for pred in preds]\n",
    "(binary_predictions!=y_test_light).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f683abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 74ms/step - AUC: 0.5322 - Accuracy: 0.5288 - Precision: 0.5305 - Recall: 0.6157 - loss: 0.8156 - val_AUC: 0.6992 - val_Accuracy: 0.5549 - val_Precision: 0.5278 - val_Recall: 0.8932 - val_loss: 0.6815\n",
      "Epoch 2/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - AUC: 0.6733 - Accuracy: 0.6269 - Precision: 0.6235 - Recall: 0.6649 - loss: 0.6638 - val_AUC: 0.7592 - val_Accuracy: 0.6720 - val_Precision: 0.6917 - val_Recall: 0.5999 - val_loss: 0.5887\n",
      "Epoch 3/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - AUC: 0.7340 - Accuracy: 0.6654 - Precision: 0.6745 - Recall: 0.6701 - loss: 0.6175 - val_AUC: 0.7794 - val_Accuracy: 0.6896 - val_Precision: 0.6740 - val_Recall: 0.7133 - val_loss: 0.5657\n",
      "Epoch 4/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - AUC: 0.7536 - Accuracy: 0.6720 - Precision: 0.6545 - Recall: 0.7350 - loss: 0.5976 - val_AUC: 0.7836 - val_Accuracy: 0.6916 - val_Precision: 0.7257 - val_Recall: 0.5985 - val_loss: 0.5741\n",
      "Epoch 5/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - AUC: 0.7427 - Accuracy: 0.6691 - Precision: 0.6743 - Recall: 0.6650 - loss: 0.6073 - val_AUC: 0.7876 - val_Accuracy: 0.7004 - val_Precision: 0.6861 - val_Recall: 0.7193 - val_loss: 0.5558\n",
      "Epoch 6/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - AUC: 0.7603 - Accuracy: 0.6816 - Precision: 0.6699 - Recall: 0.7191 - loss: 0.5890 - val_AUC: 0.7850 - val_Accuracy: 0.6916 - val_Precision: 0.6726 - val_Recall: 0.7253 - val_loss: 0.5535\n",
      "Epoch 7/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - AUC: 0.7623 - Accuracy: 0.6830 - Precision: 0.6796 - Recall: 0.6879 - loss: 0.5866 - val_AUC: 0.7903 - val_Accuracy: 0.6929 - val_Precision: 0.6513 - val_Recall: 0.8069 - val_loss: 0.5556\n",
      "Epoch 8/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - AUC: 0.7646 - Accuracy: 0.6835 - Precision: 0.6871 - Recall: 0.6867 - loss: 0.5847 - val_AUC: 0.7968 - val_Accuracy: 0.7026 - val_Precision: 0.7215 - val_Recall: 0.6430 - val_loss: 0.5448\n",
      "Epoch 9/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - AUC: 0.7687 - Accuracy: 0.6851 - Precision: 0.6962 - Recall: 0.6589 - loss: 0.5790 - val_AUC: 0.7977 - val_Accuracy: 0.7030 - val_Precision: 0.6637 - val_Recall: 0.8016 - val_loss: 0.5441\n",
      "Epoch 10/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - AUC: 0.7709 - Accuracy: 0.6948 - Precision: 0.6969 - Recall: 0.6970 - loss: 0.5787 - val_AUC: 0.8007 - val_Accuracy: 0.7049 - val_Precision: 0.7200 - val_Recall: 0.6536 - val_loss: 0.5414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2f69a4500>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del clf\n",
    "clf = get_clf(dropout=0.2,shape=x_train_gluon.shape[1:])\n",
    "clf.compile(optimizer=\"adam\", loss=loss_fn, metrics=[\"Accuracy\", \"AUC\", \"Precision\", \"Recall\"])\n",
    "\n",
    "clf.fit(\n",
    "    x_train_gluon,\n",
    "    y_train_gluon,\n",
    "    epochs=50,\n",
    "    batch_size=250,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5c0167",
   "metadata": {},
   "source": [
    "### Now take a look at boosted decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09a8f81",
   "metadata": {},
   "source": [
    "For now, try the boosted decision tree where the features are the pt of all particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1110fe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shape = x_train_orig.shape\n",
    "test_shape = x_test_orig.shape\n",
    "x_train_0_bdt = np.reshape( x_train_orig,(train_shape[0],train_shape[1]*train_shape[4]) )\n",
    "x_test_0_bdt = np.reshape( x_test_orig,(test_shape[0],test_shape[1]*test_shape[4]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ef77887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# create model instance\n",
    "bst = XGBClassifier(objective='binary:logistic', learning_rate = 0.1,\n",
    "              max_depth = 15, n_estimators = 50)\n",
    "# fit model\n",
    "bst.fit(x_train_0_bdt, y_train_orig)\n",
    "# make predictions\n",
    "preds = bst.predict(x_test_0_bdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb46f707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1774"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((y_test_orig==1) & (preds==1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5479bbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1725"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((y_test_orig==0) & (preds==0)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3081d8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9895361990950227"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test_orig==preds).sum() / len(y_test_orig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
